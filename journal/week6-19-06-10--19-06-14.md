# Week 6: 19-06-10 to 19-06-14

## **Plan for the week**

### 1) Scrape all the data from diabetes forum: https://www.diabetes.co.uk/forum/

- [ x ] Scrape the number of posts and comments per topic & totals
- [ x ] Scrape the subforum titles and their threads info
- [ x ] Scrape the thread's posts 
- [ x ] Scrape the source html pages for the whole website

### 2) Interrogative sentences

- [ x ] Research on tools to find interrogative sentences
  - Conclusion: There is two options:
    - **Option 1**: Use supervised learning:
      - Need a datasets of interrogative sentences vs non interrogative ones
      - Idea proposed: Find datasets with only interrogative sentences. Find datasets with non interrogative sentences. Build your own labeled datasets by combing the two. (TODO: find datasets)
      - Link 1.1: Chapter 6 section 2.2 of the NLTK book: https://datascience.stackexchange.com/questions/26427/how-to-extract-question-s-from-document-with-nltk
      - Link 1.2: https://stackoverflow.com/questions/49100615/nltk-detecting-whether-a-sentence-is-interogative-or-not
      - Link 1.3: https://datascience.stackexchange.com/questions/26427/how-to-extract-question-s-from-document-with-nltk
    - **Options 2**: Use POS tagging for the whole sentence. Basically, build a grammar tree of each sentences:
      - When Stanford Core NLP parse a sentence it adds a tag to the whole sentence and categorize it in different types of sentences.
      - Link 2.1: https://stackoverflow.com/questions/17879551/nltk-find-if-a-sentence-is-in-a-questioning-form
  - Link 0.1: https://stackoverflow.com/questions/4083060/determine-if-a-sentence-is-an-inquiry
  - Link 0.2: Categorizing and Tagging Words: https://www.nltk.org/book/ch05.html
  
### 3) Python project

- [ ~ ] Structure a scalable python project

## Monday

- Finished the script for scraping threads (had a lot of exceptions to consider)
- Started scraping threads (*Encountered a problem*: I was wondering if it would happen and yes it did... We can't scrape too much data at the same time, after a certain amount of pages scraped we get rate-limited and it takes forever to finish scraping the data. Because of this problem, I only have less than 5% of the desired data)
  
## Tuesday

- Continued scraping data: Found an alternative technique to scrape faster: it takes more manual work, but it scrapes pages faster^^ (I still have a bit of data to scrape)
- Encountered problems while scraping the data and fixed them
- Created script to format scraped data in csv files
- Found potential script for finding interrogative sentences
  
## Wednesday

- Continued scraping data (Almost finished)
- Started compiling the data between the two computer I used
- Going to an event with IVADO at the end of the afternoon
  
## Thursday

- Researched on tools to find interrogative sentences
- Researched on POS and Sentence Structure parsing 
- Structured a python project to have a more modular approach
- Created small sample datasets from the scraped data

## Friday

- Implemented new code to retrieve data from the new scraped data
- Refactored code
- Implemented POS tagging 
- Implemented TF-IDF
- TODO:
- Implement Stanford CoreNLP and see the different types of Grammar trees
- Learn and implement Association Rule Mining -> Find most frequent pattern -> See Apriori algorithm
- For more details see journal/week7... -> Plan of the week  
  
### CMU: Carnegie Mellon University

- CMU: https://www.cmu.edu/
- James D. Herbsleb: https://herbsleb.org/
- Societal Computing Faculty Highlight: Bogdan Vasilescu: https://www.youtube.com/watch?v=BFarCOdKOaQ
