# Week 2: 19-05-13 to 19-05-17

## Monday

- Read

## Tuesday

### **Jupyter Notebook Setup with VS Code**

[See documentation](https://code.visualstudio.com/docs/python/jupyter-support)

Cell types : `#%%` and `#%% [markdown]`

#### Export a Jupyter notebook

1. Ctrl+Shift+P
2. Export 
    - Python: Export Current Python File as Jupyter Notebook
    - Python: Export Current Python File and Output as Jupyter Notebook
    - Python: Export Python Interactive window as Jupyter Notebook

### **Can we scrape TripAdvisor?**

*Web Scraping and Crawling Are Perfectly Legal, Right?* : https://benbernardblog.com/web-scraping-and-crawling-are-perfectly-legal-right/

*Is explicit permission from websites required for data scraping to be used for research purposes?*: https://www.quora.com/Is-explicit-permission-from-websites-required-for-data-scraping-to-be-used-for-research-purposes

*TripAdvisor Robots.txt*: https://www.tripadvisor.fr/robots.txt

*How to Read and Respect Robots.txt*: https://www.promptcloud.com/blog/how-to-read-and-respect-robots-file/

*How to Create the Perfect Robots.txt File for SEO*: https://neilpatel.com/blog/robots-txt/

*TripAdvisor : Asking permission to use data for research ?* https://www.researchgate.net/post/TripAdvisor_Asking_permission_to_use_data_for_research

### **TripAdvisor Scraping**

#### General information

How can I extract data from TripAdvisor?
https://www.quora.com/How-can-I-extract-data-from-TripAdvisor

Web Scraping TripAdvisor, Text Mining and Sentiment Analysis for Hotel Reviews
https://towardsdatascience.com/scraping-tripadvisor-text-mining-and-sentiment-analysis-for-hotel-reviews-cc4e20aef333
The Python code used for web scraping TripAdvisor : https://github.com/susanli2016/NLP-with-Python/blob/master/Web%20scraping%20Hilton%20Hawaiian%20Village%20TripAdvisor%20Reviews.py
CSV file produced: https://github.com/susanli2016/Data-Analysis-with-R/blob/master/Hilton_Hawaiian_Village_Waikiki_Beach_Resort-Honolulu_Oahu_Hawaii__en.csv

How to scrape TripAdvisor.com for Hotel Data, Pricing and Reviews using Python https://www.scrapehero.com/how-to-scrape-tripadvisor/

- Scraping Logic
    1. Construct the search results page URL from TripAdvisor – Tripadvisor has complex URL for the search results page of each locality. For example here is the one for Boston https://www.tripadvisor.com/Hotels-g60745-Boston_Massachusetts-Hotels.html. We’ll have to construct this URL manually to scrape results from that page. We do that by getting this URL from Tripadvisor autocomplete API.
    2. Download HTML of the search result page using **Python Requests** – Quite easy, once you have the URL. We use python requests to download the entire HTML of this page.
    3. Parse the page using **LXML** – LXML lets you navigate the HTML Tree Structure using Xpaths. We have predefined the XPaths for the details we need in the code.
    4. Save the data to a CSV file
    5. The code : https://gist.github.com/scrapehero/1c425fdf290144cd4c7c635587feb459

#### API

TripAdvisor Content API: https://developer-tripadvisor.com/content-api/

- Does not provide the forums data
- Need an API key
- Access to an API key is not allowed for data analysis or academic research

#### Tools 

WebHarvy: https://www.webharvy.com/articles/scraping-tripadvisor.html

- Provides “access” to Posts in TripAdvisor forums
- It is a complete software (with interface, etc.) not a library. 
- Selecting which data you want to extract is be time consuming
- Not flexible

Octoparse: https://www.octoparse.com/tutorial-7/scrape-hotel-data-from-tripadvisor

- Same as WebHarvey but software seems better

<span style="color:orange">Proxycrawl:</span> https://proxycrawl.com/ 

- <span style="color:orange">Tripadvisor Reviews Scraping and Crawling Easily scrape Tripadvisor reviews with our API </span>

ScraperWorld: https://www.scraperworld.com/

- An other scraping tool
 
#### Libraries and Github repository for scraping TripAdvisor

TripAdvisor Scraper

- https://github.com/magic890/tripadvisor-scraper
- 4 years old 
- 50 stars
- Not clear what it exactly does

Scrapy-tripadvisor-reviews

- https://github.com/datascience-python/Scrapy-tripadvisor-reviews
- 2 years old
- 12 stars
- Only for reviews

Tripadvisor_crawler

- https://github.com/Tang-Li-Jen/TripAdvisor_crawler
- 4 months old
- 10 stars
- Only for hotel information (but could maybe be adapted) 

TripAdvisor-Crawling-Suite

- https://github.com/tokawah/TripAdvisor-Crawling-Suite
- 2 years old
- 8 stars
- There is no forum crawler, but we could probably add one to the suite

## Wednesday

[Canceled: we won't scrape data from TripAdvisor] TODO : Try scraping data with https://proxycrawl.com/dashboard/docs

### **Have a look at the new forums proposed**

- Women on the road: https://www.women-on-the-road.com/best-travel-forums.html
    
  - See more specific destination forums

- Frommer's: https://www.frommers.com/forums
  - Relatively small number of post 
  - Posts are more about travel experience than questions/needs

- Travellerspoint: https://www.travellerspoint.com/forum.cfm?thread=115026

### **TripAdvisor Datasets?**

Nothing relevant found...

### **Datasets?**

- Awesome Public Datasets: https://github.com/awesomedata/awesome-public-datasets

- Quora: Where can I find large datasets open to the public?: https://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public

- Microsoft Research Open Data: https://msropendata.com/

### **Diabetes forums**

- Diabetes.co.uk: https://www.diabetes.co.uk/forum/
- Children with diabetes: http://forums.childrenwithdiabetes.com/
- Diabetes Daily: https://www.diabetesdaily.com/forum/
- Tu Diabetes: https://tudiabetes.org/forum-guidelines/

### **Scrapping the web**

- 5 Tasty Python Web Scraping Libraries: https://elitedatascience.com/python-web-scraping-libraries

- Requests Quickstart: https://2.python-requests.org//en/master/user/quickstart/

- Beautiful Soup Documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/

- Web Scraping Workshop: https://gist.github.com/bradmontgomery/1872970

## Thursday

### **Finishing sample for tests**

- Added code for exporting forum test question data in .csv file
- Highlighted the requirements that could be extracted from the forum test question see diabetesForumTestQuestionHighlighted.md
  
### **NLP resources research**

#### Resources

- [ ~ ] How to get started in NLP https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff
- [ ~ ] How do I learn Natural Language Processing? https://www.quora.com/How-do-I-learn-Natural-Language-Processing
- [ - ] Getting started in Natural Language Processing (NLP) https://monkeylearn.com/blog/getting-started-in-natural-language-processing-nlp/
- [ - ] Introduction to neural network with NLP: Using neural nets to recognize handwritten digits http://neuralnetworksanddeeplearning.com/chap1.html
- [ x ] nlp-library https://github.com/mihail911/nlp-library

#### Courses 

- CS224n: Natural Language Processing with Deep Learning http://web.stanford.edu/class/cs224n/index.html#coursework
  - Youtube CS224N: Natural Language Processing with Deep Learning | Winter 2019 https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z   
- Hands-On NLTK Tutorial https://github.com/hb20007/hands-on-nltk-tutorial

#### Differences between the technologies

- **NLTK** 
  - is used primarily for general NLP tasks (tokenization, POS tagging, parsing, etc.)
  - is specialized on gathering and classifying unstructured texts. If you need e.g. a POS-tagger, lemmatizer, dependeny-analyzer, etc, you'll find them there, and sometimes nowhere else. It offers a quit broad range of tools developped mainly in academic research. But: most often it is not very well optimized - involving NLTK libraries often means to accept a huge performance loss. If you do text-gathering or -preprocessing, its fine to begin with - until you found some faster alternatives.

- **Sklearn** 
  - is used primarily for machine learning (classification, clustering, etc.)
  - offers a very systematic, efficient framework for machine-learning, analyzing, ensemble methods, evaluation and validation, and hyper-parameter optimization. It is very well documented (with a lot of ready to use recipes and examples), well optimized, and covers a broad range of ‘state of the art’ machine learning and statistical methods, the latter especially for evaluation purposes. Due to its integrity, it is ideal to start learning ‘machine learning’.

- **Gensim** 
  - is used primarily for topic modeling and document similarity.
  - is a very well optimized, but also highly specialized, library for doing jobs in the periphery of "WORD2VEC". That is: it offers an easy, surpringly well working and swift AI-approach to unstructured raw texts, based on a shallow neural network. If you are interested in prodution, or in getting deeper insights into neural networks, you might also have a look on TensorFlow, which offers a mathematically more generalized model, yet to be paid by some ‘unpolished’ performance and scalability issues by now.

- **Conclusion** 

  - Although considerably overlapping, I personally prefer using NLTK for the pre-processing of natural text (i.e., gathering, wrangling, stemming, POS-tagging, filtering and ‘noise’-reduction), GENSIM as kind of base platform (for autoencoding, semantic (topics) and syntactic (sequence) pattern- and as such for similiarity- recognition, dimensionality reduction, and for multilabel classification), and SKLEARN, which easily can be mixed up with NLTK and GENSIM, for third step evaluation / ensembling / optimizing / processing issues.

From: https://www.quora.com/When-is-better-to-use-NLTK-vs-Sklearn-vs-Gensim
  
## Friday

### **Extracting sentences containing requirements keywords**

- See Exercise2.py

### **NLP resources research 2**

- [ x ] How to Clean Text for Machine Learning with Python https://machinelearningmastery.com/clean-text-machine-learning-python/
- [ ~ ] Natural Language Processing (NLP) Techniques for Extracting Information
"Cruising the Data Ocean" Blog Series - Part 4 of 6 https://www.searchtechnologies.com/blog/natural-language-processing-techniques
- [ - ] A Practitioner's Guide to Natural Language Processing (Part I) — Processing & Understanding Text https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72
- [ ~ ] Community Forums Meets Data Science https://towardsdatascience.com/community-forums-meets-data-science-d76df98a291a
- [ ~ ] Gensim Tutorial – A Complete Beginners Guide https://www.machinelearningplus.com/nlp/gensim-tutorial/
- BERT
  - [ x ] Best NLP Model Ever? Google BERT Sets New Standards in 11 Language Tasks https://medium.com/syncedreview/best-nlp-model-ever-google-bert-sets-new-standards-in-11-language-tasks-4a2a189bc155
  - [ - ] bert-as-service Documentation https://bert-as-service.readthedocs.io/en/latest/
  - [ - ] Repo https://github.com/llSourcell/bert-as-service
  - [ - ] paper’s code and data on Github. https://github.com/brightmart/bert_language_understanding


## TODO:

Scalable do-it-yourself scraping – How to build and run scrapers on a large scale https://www.scrapehero.com/scalable-do-it-yourself-scraping-how-to-build-and-run-scrapers-on-a-large-scale/

How to prevent getting blacklisted while scraping
 https://www.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/


