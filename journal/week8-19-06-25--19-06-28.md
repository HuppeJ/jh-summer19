# Week 8: 19-06-25--19-06-28

## **Plan for the week**

## 1) Things to implement

## 2) **Ideas to explore**

- [ - ] Use title to get more info about the thread and distinguish the noisy data form the non-noisy data
- [ - ] Focus on question post and use the answer posts to bring more information
- [ - ] Find the need from the answer posts: find sentence structures that answer a need
- [ - ] Summary/Topic modeling for the whole conversation? 
- [ - ] Summary/Topic modeling for each post?
  - For now we will only use the title and see if topic modeling could help later [14/06/2019] 
  - topic-modelling-with-spacy-and-scikit-learn: https://www.kaggle.com/thebrownviking20/topic-modelling-with-spacy-and-scikit-learn
- [ - ] Consider the position of the sentence.

## 4) **Things to research and learn about**:

- [ - ] Association rule mining -> Find most frequent pattern -> See Apriori algorithm etc.
- [ - ] How to reduce noise in forum conversation?
- [ - ] What techniques are used to optimize search result based on the search query
- [ - ] Find patterns in sentences that certainly do not express a need?

## **Things to keep in mind**

- [ - ] spaCy really good NLP library: https://spacy.io/
  - [ ~ ] spaCy vs NLTK: https://medium.com/@pemagrg/private-nltk-vs-spacy-3926b3674ee4
  
## Monday

- Fête nationale du Québec: Saint-Jean-Baptiste
  
## Tuesday

### Amazon turk

- MTurk Tutorials: https://blog.mturk.com/tutorials/home
- Getting Started with MTurk to Gather Training Data for AI and ML: https://medium.com/@mechanicalturk/getting-started-with-mturk-to-gather-training-data-for-ai-and-ml-99768f6ec3c2
  - Tutorial: A beginner’s guide to crowdsourcing ML training data with Python and MTurk https://blog.mturk.com/tutorial-a-beginners-guide-to-crowdsourcing-ml-training-data-with-python-and-mturk-d8df4bdf2977
  - Tutorial: How to verify crowdsourced training data using a Known Answer Review Policy: https://blog.mturk.com/tutorial-how-to-verify-crowdsourced-training-data-using-a-known-answer-review-policy-85596fb55ed
- Using CSV Files to Create Multiple HITs in the Requester UI: https://blog.mturk.com/using-csv-files-to-create-multiple-hits-in-the-requester-ui-22a25ec563dc
- Tutorial: Using Crowd HTML Elements: https://blog.mturk.com/tutorial-using-crowd-html-elements-b8990ec71057
- Effective Use of Amazon Mechanical Turk (MTurk): https://neerajkumar.org/writings/mturk/

DONE : 

- Read on Amazon Turk
- Sample some sentences
- Wrote examples of sentences
- Wrote list of questions and verifications before submitting 
- Prepare two sets for amazon mechanical turk
  - 1: Interrogative sentences
  - 2: Keywords + non keywords sentences
- Created html layout for questions in Amazon Turk
- Created Sandbox with sample sentences: https://requestersandbox.mturk.com/create/projects/86497/batches/241891/preview?number=1

TODO 

- Check [ Questions/Verifications ] for Amazon Turk
- Submit to Amazon Turk
- Analyse data and find if first posts of each threads have more information
- Work & read on extractive summary
  - Extractive summary of whole threads?
  - Extractive summary of each comments?

## Wednesday

### Associative Rules Mining:

- association rules (in data mining): https://searchbusinessanalytics.techtarget.com/definition/association-rules-in-data-mining
- Frequent Pattern Mining and the Apriori Algorithm: A Concise Technical Overview: https://www.kdnuggets.com/2016/10/association-rule-learning-concise-technical-overview.html
- Lecture 20 — Frequent Itemsets | Mining of Massive Datasets | Stanford University: https://www.youtube.com/watch?v=O9QnC5WJJ90
- Frequent Itemsets via Apriori Algorithm: http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/#example-1-generating-frequent-itemsets

DONE : 

- Adjusted details for Amazon mTurk
- Deployment of Amazon mTurk on hold (still verifications to make)
- Read about Associative Rules Mining: Apriori Algorithm  
- Read about Extractive summarization

TODO : 

- Create new sample datasets of 3x3500 sentences (we want one csv file with all 10500 sentences)
  - #1 sample of the sample: 1000 of them to test 0_to_999_sample
  - #2 the rest 1000_to_10500_sample
- If no gift card Send to Maleknaz HTML layout and everything needed for mTurk
- Read papers on summarization
- For each thread from the sample submitted to mTurk take all the messages group them and apply extractive summarization on them
- Extractive summarization: see which algo to use.
- Submit to Amazon Turk?
- Monitor the results tomorrow 
  
## Thursday

- awesome-text-summarization: https://github.com/mathsyouth/awesome-text-summarization#extractive-text-summarization
- **BERT SUMMARIZER**:
- Leveraging BERT for Extractive Text Summarization on Lectures: https://arxiv.org/abs/1906.04165 & https://arxiv.org/ftp/arxiv/papers/1906/1906.04165.pdf
  - lecture-summarizer GitHub: https://github.com/dmmiller612/lecture-summarizer/tree/master/summarizer
  - bert-extractive-summarizer 0.1.4: https://pypi.org/project/bert-extractive-summarizer/

DONE : 

- Created new sample datasets of 3x3500 sentences (one csv file with all 10500 sentences)
  - #1 sample of the sample: 1000 of them to test 0_to_999_sample
  - #2 the rest 1000_to_10500_sample
- Prepared and sent datasets, instructions and HTML layout for mturk
- Read 4. ESSMArT Way to Manage User Requests (about Extractive Summarization)
- Read 5. Text Summarization Techniques A Brief Survey
- Experimented with bert-extractive-summarizer
- Worked on extracting thread text for summarization. The script is finished, but there is a little bug with newline characters in csv file

TODO :

- Find desired extractive summarization algorithm 
- Run desired extractive summarization algorithm on the datasets
- Read Ani Nenkova and Amit Bagga. 2004. Facilitating email thread access by extractive
summary generation. ?

## Friday

- Use-cases of Google’s Universal Sentence Encoder in Production:https://towardsdatascience.com/use-cases-of-googles-universal-sentence-encoder-in-production-dd5aaab4fc15
- bert-as-service:https://github.com/hanxiao/bert-as-service#building-a-qa-semantic-search-engine-in-3-minutes
- Serving Google BERT in Production using Tensorflow and ZeroMQ: https://hanxiao.github.io/2019/01/02/Serving-Google-BERT-in-Production-using-Tensorflow-and-ZeroMQ/
- Universal Sentence Encoder: https://arxiv.org/abs/1803.11175

DONE : 

- Extracted thread text for summarization.
- Experimented with LexRank summarization with a lexrank library/project
- Experimented with LexRank summarization with sumy library
- Implemented and ran script to summarize all the thread text
- Researched for new techniques and came up with new ideas 

TODO :

- Read Ani Nenkova and Amit Bagga. 2004. Facilitating email thread access by extractive
summary generation. ?
- Analyse mTurk data?
- Implement new ideas?
